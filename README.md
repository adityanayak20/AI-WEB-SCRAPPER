# ğŸ  AI Web Scraper (Selenium + LangChain + Streamlit)

This project scrapes property listings from a given URL (e.g., [PropertyFinder.ae](https://www.propertyfinder.ae)), then uses **LangChain + Ollama (LLaMA model)** to parse and organize the scraped content into a structured table.  
The data is shown in a **Streamlit web UI** where you can interact with the results.

---

## ğŸ“‚ Project Structure

- **`Dockerfile`** â€“ Defines the runtime environment, installs Python + required packages.  
- **`docker-compose.yml`** â€“ Orchestrates services:  
  - `scraper` â†’ Runs Streamlit app.  
  - `ollama` â†’ Runs Ollama model backend.  
- **`run.sh`** â€“ One-command build & run script for the whole project.  
- **`main.py`** â€“ Streamlit frontend (user inputs + display).  
- **`scrape.py`** â€“ Scraping logic (fetches raw HTML, extracts useful sections).  
- **`parse.py`** â€“ Parsing helpers (turn HTML â†’ structured rows of data).  

---

## âš™ï¸ Prerequisites

- [Docker](https://docs.docker.com/get-docker/) installed  
- [Docker Compose](https://docs.docker.com/compose/install/) installed  
- ~5 GB free space (Ollama model `llama3:latest` will be pulled automatically the first time)  

---

## ğŸš€ How to Run

1. **Clone the repository**
   ```bash
   git clone https://github.com/adityanayak20/AI-WEB-SCRAPPER.git
   cd <repo-folder>

	2.	Make the run script executable

chmod +x run.sh


	3.	Start the project

./run.sh

This will:
	â€¢	Build the Docker image
	â€¢	Start ollama and scraper containers
	â€¢	Launch the Streamlit app

	4.	Open the UI
Navigate to: http://localhost:8501

â¸»

ğŸ›ï¸ Using the App

The UI has three input fields:
	1.	Page URL
Paste the property search page URL. Example:

https://www.propertyfinder.ae/en/search?l=733&c=2&fu=0&rp=y&ob=mr


	2.	Ask the AI about this page (free-text prompt)
Example prompts:

Can you please collect all of the relevant property information and organize it in a table.

Can you please collect all of the relevant property information and organize it in a table. And Please give the complete data as much possible


	3.	Ollama model
Default is:

llama3:latest



â¸»

ğŸ–¥ï¸ Example Workflow
	1.	Start the app with ./run.sh.
	2.	Open http://localhost:8501.
	3.	Paste your property search URL.
	4.	Enter a natural language prompt (e.g., â€œSummarize all listings in a tableâ€).
	5.	Select llama3:latest.
	6.	Click Scrape & Ask.
	7.	View the AI-generated table of property listings ğŸ‰

â¸»

ğŸ“¦ Output
	â€¢	The scraped + parsed listings are displayed in the UI as a structured table.
	â€¢	You can copy/paste or export results directly from Streamlit.

â¸»

ğŸ› ï¸ Notes
	â€¢	The first run may take longer because the LLaMA model (~4â€“5 GB) will be downloaded.
	â€¢	The model is cached by Ollama and reused for future runs (across other AI projects too).
	â€¢	Ethical scraping: respect target websitesâ€™ terms of service and add delays if scaling up.

â¸»